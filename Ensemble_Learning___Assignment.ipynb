{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: What is Ensemble Learning in machine learning? Explain the key idea behind it.\n",
        "\n",
        "Answer: nsemble Learning means combining many models (like Decision Trees, Logistic Regression, etc.) to make one strong model that performs better than any single one.\n",
        "\n",
        "The main idea is “many weak models together can make a strong model.”\n",
        "\n",
        "Each model (called a base learner) learns differently. When we combine their predictions, the errors of one model can be corrected by others, leading to better accuracy and stability.\n",
        "\n",
        "## Question 2: What is the difference between Bagging and Boosting?\n",
        "\n",
        "\n",
        "Answer:\n",
        "\n",
        "Bagging :\n",
        "\n",
        "Bagging is a method in ensemble learning where many models are trained separately on different random samples of the same dataset.\n",
        "Each sample is created by picking data points with replacement (some may repeat, some may be missed).\n",
        "\n",
        "All models are trained independently, and in the end, their results are combined — usually by taking a majority vote (for classification) or average (for regression).\n",
        "\n",
        "This technique helps to reduce variance, meaning the model becomes more stable and less likely to overfit the training data.\n",
        "\n",
        "Boosting:\n",
        "\n",
        "Boosting is another ensemble method, but here, models are trained one after another.\n",
        "Each new model tries to fix the mistakes made by the previous ones.\n",
        "In this way, boosting focuses more on difficult examples that earlier models got wrong.\n",
        "\n",
        "As more models are added, the system becomes stronger and more accurate.\n",
        "Boosting helps to reduce bias and build a highly accurate model, but it can sometimes lead to overfitting if not controlled.\n",
        "\n",
        "## Question 3: What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?\n",
        "\n",
        "Answer: Bootstrap sampling means randomly selecting data points from the original dataset with replacement to create many new samples.\n",
        "Each sample is called a bootstrap sample and is usually the same size as the original dataset.\n",
        "Because the sampling is with replacement, some data points may appear more than once, while others may be left out.\n",
        "\n",
        " It play in Bagging methods like Random Forest as :\n",
        "\n",
        "\n",
        "In Bagging methods such as Random Forest, bootstrap sampling is used to create different training sets for each model (for example, each Decision Tree).\n",
        "\n",
        "Since each tree gets a slightly different dataset:\n",
        "\n",
        "* The trees learn different patterns.\n",
        "\n",
        "* Their errors are less correlated.\n",
        "\n",
        " When all trees vote together, the final result becomes more accurate and stable.\n",
        "\n",
        "So, bootstrap sampling increases diversity among models, which helps Bagging reduce variance and overfitting.\n",
        "\n",
        "\n",
        "## Question 4: What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?\n",
        "\n",
        "Answer: When we do bootstrap sampling (sampling with replacement), some data points are not chosen for that sample.\n",
        "These left-out data points are called Out-of-Bag (OOB) samples.\n",
        "\n",
        "Usually, around one-third of the data becomes OOB for each model.\n",
        "\n",
        "To evaluate ensemble models as :\n",
        "\n",
        "In Bagging models like Random Forest, OOB samples are used to test the model’s performance — without needing a separate validation set.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "Each tree in the forest is trained on its bootstrap sample.\n",
        "\n",
        "The OOB samples (data not used for training that tree) are passed through that tree to get predictions.\n",
        "\n",
        "After doing this for all trees, we compare the combined OOB predictions with the true labels.\n",
        "\n",
        "The OOB score is the average accuracy (or error rate) computed using these predictions.\n",
        "\n",
        "## Question 5: Compare feature importance analysis in a single Decision Tree vs. a Random Forest.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Feature Importance in a Single Decision Tree:\n",
        "\n",
        "In one Decision Tree, feature importance is measured by how much a feature reduces impurity (like Gini or Entropy) when it’s used to split the data.\n",
        "\n",
        "* Each time a feature is used to split, we calculate how much the impurity decreases.\n",
        "\n",
        "* All decreases caused by that feature are added up.\n",
        "\n",
        "* The feature with the highest total decrease is the most important.\n",
        "\n",
        "Feature Importance in a Random Forest:\n",
        "\n",
        "A Random Forest is made of many trees, each trained on a different bootstrap sample and random set of features.\n",
        "\n",
        "* For each feature, the Random Forest calculates the average impurity decrease across all trees.\n",
        "\n",
        "* These scores are then normalized to show overall importance.\n",
        "\n",
        "Because it combines many trees, Random Forest gives more reliable and stable feature importance values. It also reduces the bias that can happen in a single tree."
      ],
      "metadata": {
        "id": "8j6JS3clPHzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6: Write a Python program to:\n",
        "# ● Load the Breast Cancer dataset using sklearn.datasets.load_breast_cancer()\n",
        "# ● Train a Random Forest Classifier\n",
        "# ● Print the top 5 most important features based on feature importance scores.\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#  Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "#  Get feature importance scores\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better display\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': data.feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "#  Sort by importance and show top 5\n",
        "top5 = feature_importance_df.sort_values(by='Importance', ascending=False).head(5)\n",
        "\n",
        "# Print the top 5 important features\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(top5)\n"
      ],
      "metadata": {
        "id": "2q2xc9OsQCAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea9ab8b-ceeb-4adf-facb-e4c7dcd903fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "                 Feature  Importance\n",
            "23            worst area    0.139357\n",
            "27  worst concave points    0.132225\n",
            "7    mean concave points    0.107046\n",
            "20          worst radius    0.082848\n",
            "22       worst perimeter    0.080850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Write a Python program to:\n",
        "# ● Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "# ● Evaluate its accuracy and compare with a single Decision Tree\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#  Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#  Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "#  Train a single Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "#  Train a Bagging Classifier using Decision Trees\n",
        "# use 'base_estimator' instead of 'estimator' if your sklearn is older\n",
        "try:\n",
        "    bag_model = BaggingClassifier(\n",
        "        estimator=DecisionTreeClassifier(),\n",
        "        n_estimators=50,\n",
        "        random_state=42\n",
        "    )\n",
        "except TypeError:\n",
        "    bag_model = BaggingClassifier(\n",
        "        base_estimator=DecisionTreeClassifier(),\n",
        "        n_estimators=50,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "bag_model.fit(X_train, y_train)\n",
        "bag_pred = bag_model.predict(X_test)\n",
        "bag_accuracy = accuracy_score(y_test, bag_pred)\n",
        "\n",
        "# Print accuracy comparison\n",
        "print(\"Accuracy of Single Decision Tree:\", round(dt_accuracy, 3))\n",
        "print(\"Accuracy of Bagging Classifier:  \", round(bag_accuracy, 3))\n",
        "\n"
      ],
      "metadata": {
        "id": "7cVgPlgpQs3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87d22fa-a230-4928-bddc-300468e6854b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Single Decision Tree: 1.0\n",
            "Accuracy of Bagging Classifier:   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Write a Python program to:\n",
        "# ● Train a Random Forest Classifier\n",
        "# ● Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "# ● Print the best parameters and final accuracy\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#  Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#  Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "#  Define the Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "#  Define hyperparameter grid to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7, None]\n",
        "}\n",
        "\n",
        "#  Use GridSearchCV for tuning\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,              # 5-fold cross validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "#  Train the model with GridSearch\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "#  Get the best parameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "#  Evaluate final accuracy\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#  Print results\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Final Accuracy:\", round(accuracy, 3))\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8AM7U9IQ55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8be001-06f2-4806-c1dd-dde265689795"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 3, 'n_estimators': 150}\n",
            "Final Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Write a Python program to:\n",
        "# ● Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset\n",
        "# ● Compare their Mean Squared Errors (MSE)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.datasets import load_diabetes   # built-in regression dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#  Load a built-in regression dataset (no internet needed)\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#  Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "#  Train a Bagging Regressor using Decision Trees\n",
        "bag_model = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_model.fit(X_train, y_train)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "#  Make predictions\n",
        "bag_pred = bag_model.predict(X_test)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "#  Calculate Mean Squared Errors (MSE)\n",
        "bag_mse = mean_squared_error(y_test, bag_pred)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "#  Print comparison\n",
        "print(\"Mean Squared Error (Bagging Regressor):\", round(bag_mse, 3))\n",
        "print(\"Mean Squared Error (Random Forest Regressor):\", round(rf_mse, 3))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KFeigwowRJe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b64fc0e-a3a2-4316-e2aa-090361b4df77"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Bagging Regressor): 2987.007\n",
            "Mean Squared Error (Random Forest Regressor): 2932.051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10: You are working as a data scientist at a financial institution to predict loan default. You have access to customer demographic and transaction history data.\n",
        "\n",
        "\n",
        "## You decide to use ensemble techniques to increase model performance.\n",
        "\n",
        "##Explain your step-by-step approach to:\n",
        "## ● Choose between Bagging or Boosting\n",
        "## ● Handle overfitting\n",
        "## ● Select base models\n",
        "## ● Evaluate performance using cross-validation\n",
        "## ● Justify how ensemble learning improves decision-making in this real-world context.\n",
        "\n",
        "Answer :\n",
        "\n",
        "\n",
        "1) Choose Bagging or Boosting —\n",
        "\n",
        "*  Use Bagging (e.g., Random Forest) when:\n",
        "\n",
        "     * Data is noisy or has outliers.\n",
        "\n",
        "     * You want a stable model that’s less likely to overfit.\n",
        "\n",
        "     * You need fast parallel training.\n",
        "\n",
        "* Use Boosting (e.g., XGBoost, LightGBM) when:\n",
        "\n",
        "     * You need top accuracy and can spend more time tuning.\n",
        "\n",
        "     * The problem has complex patterns and many weak signals.\n",
        "\n",
        "    *  Data is mostly clean (boosting can overfit noisy labels).\n",
        "\n",
        "* Practical pick for finance: start with Boosting (LightGBM / XGBoost) for best predictive power, but try Random Forest as a baseline.\n",
        "\n",
        "2) Handle overfitting — concrete steps\n",
        "\n",
        "* Regularize models\n",
        "\n",
        "     * For trees: limit max_depth, min_samples_leaf, min_samples_split.\n",
        "\n",
        "     * For boosting: use learning_rate, subsample, colsample_bytree, lambda/alpha.\n",
        "\n",
        "* Early stopping on a validation set (stop training when val loss stops improving).\n",
        "\n",
        "* Use cross-validation (see next) to detect overfitting.\n",
        "\n",
        "* Feature work: remove low-info features, avoid data leakage, use domain-driven feature selection.\n",
        "\n",
        "* Use balanced sampling / class weights if defaults are rare.\n",
        "\n",
        "* Calibration: check probability calibration (Platt or isotonic), important for decision thresholds.\n",
        "\n",
        "* Model pruning / simpler models if complexity doesn’t help.\n",
        "\n",
        "\n",
        "3) Select base models\n",
        "\n",
        "* Trees are first choice: DecisionTree, RandomForest, XGBoost, LightGBM, CatBoost.\n",
        "\n",
        "* For stacking ensembles: combine diverse learners — e.g., Logistic Regression (good calibrated probs), Random Forest, XGBoost.\n",
        "\n",
        "* Why mix? Different model families learn different patterns; stacking can capture that.\n",
        "\n",
        "* Practical setup: baseline = logistic regression, strong learner = LightGBM, ensemble = stacked blend of LR + RF + LightGBM.\n",
        "\n",
        "\n",
        "4) Evaluate with cross-validation (how-to)\n",
        "\n",
        "* Use stratified K-Fold (preserve class ratios), e.g., K=5 or 10.\n",
        "\n",
        "* If data has time order (transactions over time) → use time-based splits (rolling window).\n",
        "\n",
        "* Metrics to log:\n",
        "\n",
        "    * AUC-ROC (ranking ability)\n",
        "\n",
        "    * Precision@k, Recall, F1 (for rare default class)\n",
        "\n",
        "     * Precision-Recall AUC if class is very imbalanced\n",
        "\n",
        "* Expected monetary loss (use cost matrix: false negative cost >> false positive)\n",
        "\n",
        "* Calibration / Brier score for probability quality\n",
        "\n",
        "* Use nested CV or separate holdout for final model selection to avoid leakage.\n",
        "\n",
        "* Uncertainty: compute confidence intervals of CV scores.\n",
        "\n",
        "5) Practical checks & production readiness\n",
        "\n",
        "* Explainability: compute SHAP values, global feature importance, and local explanations for flagged loans.\n",
        "\n",
        "* Fairness & compliance: check performance by group (age, gender, region) and document model decisions.\n",
        "\n",
        "* Monitoring: track model drift, feature drift, and real-world default rate vs predicted.\n",
        "\n",
        "*  Latency & cost: boosting models are fast at prediction, but stacking adds overhead — choose based on latency needs.\n",
        "\n",
        "6) Why ensemble learning helps decisions\n",
        "\n",
        "* Better accuracy: combines many learners to reduce bias/variance → fewer wrong decisions.\n",
        "\n",
        "* More stable predictions: reduces sensitivity to single bad model or noisy data.\n",
        "\n",
        "* Richer signals: ensembles capture complex feature interactions that simple models miss.\n",
        "\n",
        "* Better risk control: higher-quality probabilities lead to better credit limits, pricing, and fraud flags.\n",
        "\n",
        "* BUT: ensembles can be complex — you must add explainability and monitoring to meet regulatory needs"
      ],
      "metadata": {
        "id": "KUJoIpUaRR2_"
      }
    }
  ]
}